\section{Introduction} \label{sec:intro}


\subsection{Questions}

We address these two questions in this project.
First, we plan to \textit{map} a given workload comprised of
a set of SQL transactions to a standard database benchmark workload. 
This problem is independent of the underlying DBMS or hardware configuration.
This will allow us to use prior knowledge about the standard 
benchmark gained from previous DBMS deployments. 

We collect features that characterize the SQL workload as well as 
DBMS statistics.
It will be interesting to see if feature extraction yields insights
about the most influential features.
We then use unsupervised techniques like \textit{clustering} 
for mapping the workloads.
Performance analysis of the resulting classifier is done via
cross-validation.

Second, we plan to \textit{estimate} the DBMS performance given a 
DBMS configuration, hardware setup and SQL workload. 
This will be done with supervised techniques like 
\textit{Gaussian process regression}.
As we expect a lot of features to be present in the input, we may
need to make use of a feature extraction algorithm like
principal component analysis (PCA) first.
Performance analysis of the estimator will also be done using 
cross-validation.
We describe our progress on solving the first problem in this report.

\subsection{Minimum goals}
The minimum goals are : (a) to create a workload mapper that maps an arbitrary
SQL workload to a well-known standard benchmark, and (b) to estimate the
performance of a DBMS given a workload and configuration pair.

We have already achieved the first goal on our dataset. We plan to
generalize it to more sophisticated datasets as our stretch goal. 
We have also setup the infrastructure required 
for achieving the second goal.

\subsection{Stretch goals}
As a real-world workload can exhibit some aspects of different standard
benchmarks or can exhibit different characteristics across time (e.g. read-mostly
during day and write-mostly during night), mapping the entire workload onto
a single benchmark may not be an entirely accurate characterization.
To help characterize the workload more accurately, we will consider mapping
parts of a workload onto different benchmarks using techniques like
\textit{multi-label prediction}.

% Can we skip this for now ?
%Second, we can use \textit{Bayesian optimization} to find the
%optimal configuration that can deliver highest performance given
%information about the workload and hardware setup. We think that this is a
%hard problem since the state space is large.

In this report, we first describe how we generate the dataset in
\cref{sec:data_set}. We then focus on the feature extraction problem
in \cref{sec:features}.
Finally, we sketch our initial evaluation results in \cref{sec:eval}.
